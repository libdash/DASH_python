{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcddecbf",
   "metadata": {},
   "source": [
    "# {index}`GSS 2020 data <single: GSS 2020 data>`\n",
    "\n",
    "```{index} single: Python; GSS 2020 data\n",
    "```\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this section we perform data analysis on 2020 GSS data. We cover the following concepts:\n",
    "\n",
    "* Univariate/Bivariate analysis\n",
    "* Data cleaning \n",
    "* Data manipulation\n",
    "* Anova\n",
    "* etc\n",
    "\n",
    "\n",
    "### Univariate/Bivariate analysis\n",
    "\n",
    "Univariate and bivariate analyses are essential steps in exploratory data analysis (EDA). They help you understand the distribution and relationships of variables in your dataset. Here’s a step-by-step guide for each:\n",
    "\n",
    "#### Univariate Analysis\n",
    "\n",
    "Univariate analysis examines the distribution of a single variable. The goal is to understand the central tendency, dispersion, and shape of the variable’s distribution.\n",
    "\n",
    "Steps:\n",
    "1. Identify the Variable Type:\n",
    "   * Categorical (e.g., gender, color): Non-numeric data that represent categories.\n",
    "   * Numerical (e.g., age, income): Numeric data that can be discrete or continuous.\n",
    "  \n",
    "2. Descriptive Statistics:\n",
    "   \n",
    "   * Categorical Variables:\n",
    "     * Frequency Distribution: Count the occurrences of each category.\n",
    "     * Mode: The category with the highest frequency.\n",
    "   * Numerical Variables:\n",
    "     * Measures of Central Tendency: Mean, median, mode.\n",
    "     * Measures of Dispersion: Range, variance, standard deviation, interquartile range (IQR).\n",
    "     * Skewness & Kurtosis: To assess the shape of the distribution.\n",
    "  \n",
    "3. Visualization:\n",
    "   * Categorical Variables:\n",
    "     * Bar Chart\n",
    "     * Pie Chart\n",
    "   * Numerical Variables:\n",
    "     * Histogram\n",
    "     * Boxplot\n",
    "     * Density Plot\n",
    "  \n",
    "4. Check for Outliers: (Numerical variables)\n",
    "   * Use boxplots or z-scores to identify and assess outliers.\n",
    "\n",
    "5. Assess Distribution: (Numerical variables)\n",
    "   * Identify if the data is normally distributed or skewed using histograms and Q-Q plots.\n",
    "\n",
    "#### Bivariate Analysis\n",
    "Bivariate analysis examines the relationship between two variables. The aim is to identify patterns, correlations, or associations between them.\n",
    "\n",
    "Steps:\n",
    "1. Identify the Variable Types:\n",
    "\n",
    "   * Both Categorical\n",
    "   * Both Numerical\n",
    "   * One Categorical and One Numerical\n",
    "  \n",
    "2. Descriptive Statistics:\n",
    "   \n",
    "   * Categorical vs. Categorical:\n",
    "     * Cross-tabulation: Create a contingency table to observe the frequency of combinations of categories.\n",
    "     * Chi-Square Test: Test the independence of the variables.\n",
    "   * Numerical vs. Numerical:\n",
    "     * Correlation Coefficient: Use Pearson (linear relationships) or Spearman (non-linear relationships) to measure the strength and direction of the relationship.\n",
    "     * Covariance: Assess the direction of the relationship (positive or negative).\n",
    "   * Categorical vs. Numerical:\n",
    "        * Group Statistics: Calculate summary statistics (mean, median, etc.) for the numerical variable across different categories.\n",
    "        * T-test or ANOVA: Test the difference in means between groups.\n",
    "3. Visualization:\n",
    "\n",
    "   * Categorical vs. Categorical:\n",
    "     * Stacked Bar Chart\n",
    "     * Mosaic Plot\n",
    "   * Numerical vs. Numerical:\n",
    "        * Scatter Plot\n",
    "        * Line Chart (if time-series data)\n",
    "        * Pair Plot (for multiple numerical variables)\n",
    "   * Categorical vs. Numerical:\n",
    "        * Boxplot (by category)\n",
    "        * Violin Plot\n",
    "        * Bar Plot with error bars\n",
    "  \n",
    "4. Identify Relationships:\n",
    "\n",
    "   * Categorical vs. Categorical: Look for patterns or significant associations in the contingency table.\n",
    "   * Numerical vs. Numerical: Look for trends, clusters, or correlations in the scatter plot.\n",
    "   * Categorical vs. Numerical: Check for differences in distributions or central tendencies across categories.\n",
    "5. Hypothesis Testing:\n",
    "\n",
    "   * Conduct appropriate statistical tests to validate or reject hypotheses about the relationships between variables.\n",
    "\n",
    "\n",
    "### Step 1:\n",
    "\n",
    "If necessary, select your sample: \n",
    "For example we select those who's age are 25+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8ad791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/amirrezamousavi/Desktop/lisa/Microdata Coding Project/gss2020_small_new.csv\")\n",
    "filtered_df = df[df['AGEGR10'] > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de6ec0",
   "metadata": {},
   "source": [
    "We can run a frequency table for agegr10  to check the sample selection was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1166ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGEGR10\n",
      "3    6388\n",
      "4    5920\n",
      "5    6443\n",
      "6    5742\n",
      "7    3225\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "frequency_table = filtered_df['AGEGR10'].value_counts().sort_index()\n",
    "print(frequency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec455861",
   "metadata": {},
   "source": [
    "We can also check to see if we have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b37debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing values for each feature: PUMFID      0\n",
      "WGHT_PER    0\n",
      "AGEGR10     0\n",
      "MARSTAT     0\n",
      "PHSDFLG     0\n",
      "           ..\n",
      "LAN_01      0\n",
      "LANHSD_C    0\n",
      "LANCH_C     0\n",
      "INC_C       0\n",
      "FAMINC_C    0\n",
      "Length: 264, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"number of missing values for each feature:\",df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82628202",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "\n",
    "Removing missing values:\n",
    "\n",
    "In pandas, the [dropna()]('https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html') method is used to remove missing values (i.e., NaN values) from a DataFrame or Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22bc5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any missing values\n",
    "df_cleaned = filtered_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f5305",
   "metadata": {},
   "source": [
    "To obtain the frequency distribution of the variable vismin_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a86327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISMIN_C\n",
      "10    15568\n",
      "99     2003\n",
      "5      1948\n",
      "7      1600\n",
      "6      1532\n",
      "1      1300\n",
      "2      1254\n",
      "8      1136\n",
      "3       636\n",
      "9       446\n",
      "4       295\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get frequency distribution\n",
    "frequency_distribution = filtered_df['VISMIN_C'].value_counts()\n",
    "\n",
    "print(frequency_distribution)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17774788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variable vismin2 as a copy of vismin_c\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "filtered_df['vismin2'] = filtered_df['VISMIN_C']             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180c88c",
   "metadata": {},
   "source": [
    "recode vismin2(1 thru 9=1)(10=0)(999=sysmis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f070f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Recode values\n",
    "filtered_df['vismin2'] = filtered_df['vismin2'].replace({999: np.nan})  # Set 999 to NaN (sysmis)\n",
    "filtered_df['vismin2'] = filtered_df['vismin2'].apply(lambda x: 1 if 1 <= x <= 9 else (0 if x == 10 else np.nan))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3681f",
   "metadata": {},
   "source": [
    "In the next step we give value label to each category of the new var vismin2. \n",
    "Value labels vismin2 0'not a visible minority' 1'visible minority'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d45817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0: 'Not a Visible Minority', 1: 'Visible Minority'}\n",
    "# Apply labels\n",
    "filtered_df['vismin2_label'] = filtered_df['vismin2'].map(labels)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f542b77",
   "metadata": {},
   "source": [
    "In this section as an example we reverse code GEN_01 variable.\n",
    "recode genhealth_rev(1=5)(2=4)(3=3)(4=2)(5=1)(9=sysmis). \n",
    "value labels genhealth_rev 1'poor' 2'fair' 3'good' 4'very good' 5'excellent'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5d0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse code the variable\n",
    "filtered_df['genhealth_rev'] = filtered_df['GEN_01'].replace({9: np.nan})  # Set 9 to NaN (sysmis)\n",
    "filtered_df['genhealth_rev'] = filtered_df['genhealth_rev'].apply(lambda x: 6 - x if pd.notna(x) else np.nan)\n",
    "\n",
    "# Define labels\n",
    "labels = {1: 'Poor', 2: 'Fair', 3: 'Good', 4: 'Very Good', 5: 'Excellent'}\n",
    "\n",
    "# Apply labels\n",
    "filtered_df['genhealth_rev_label'] = filtered_df['genhealth_rev'].map(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c424a861",
   "metadata": {},
   "source": [
    "Since ratio variables are limited in the GSS data I am recoding SCF100_C (ordinal) into a ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef51ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['numfriends'] = filtered_df['SCF100_C'].replace({9: np.nan})  # Assuming 9 indicates missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beee69d",
   "metadata": {},
   "source": [
    "recode numfriends(10=14.5)(11=24.5)(12=30)(999=sysmis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f2ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['numfriends'] = filtered_df['numfriends'].replace({\n",
    "    10: 14.5,\n",
    "    11: 24.5,\n",
    "    12: 30,\n",
    "    999: np.nan  # Treat 999 as missing\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e3feb",
   "metadata": {},
   "source": [
    "To analyze the 'numfriends' variable and its relationship with 'SCF100_C', you need to generate a frequency distribution and a cross-tabulation table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c43fc289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies of numfriends:\n",
      "numfriends\n",
      "2.0     5170\n",
      "3.0     3916\n",
      "5.0     3135\n",
      "1.0     3067\n",
      "4.0     2935\n",
      "0.0     2689\n",
      "14.5    2548\n",
      "6.0     1706\n",
      "8.0      827\n",
      "7.0      532\n",
      "24.5     523\n",
      "NaN      449\n",
      "30.0     221\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cross-tabulation of numfriends by SCF100_C:\n",
      "SCF100_C      0     1     2     3     4     5     6    7    8     10   11   12\n",
      "numfriends                                                                    \n",
      "0.0         2689     0     0     0     0     0     0    0    0     0    0    0\n",
      "1.0            0  3067     0     0     0     0     0    0    0     0    0    0\n",
      "2.0            0     0  5170     0     0     0     0    0    0     0    0    0\n",
      "3.0            0     0     0  3916     0     0     0    0    0     0    0    0\n",
      "4.0            0     0     0     0  2935     0     0    0    0     0    0    0\n",
      "5.0            0     0     0     0     0  3135     0    0    0     0    0    0\n",
      "6.0            0     0     0     0     0     0  1706    0    0     0    0    0\n",
      "7.0            0     0     0     0     0     0     0  532    0     0    0    0\n",
      "8.0            0     0     0     0     0     0     0    0  827     0    0    0\n",
      "14.5           0     0     0     0     0     0     0    0    0  2548    0    0\n",
      "24.5           0     0     0     0     0     0     0    0    0     0  523    0\n",
      "30.0           0     0     0     0     0     0     0    0    0     0    0  221\n"
     ]
    }
   ],
   "source": [
    "# Frequencies\n",
    "frequency_distribution = filtered_df['numfriends'].value_counts(dropna=False)\n",
    "\n",
    "print(\"Frequencies of numfriends:\")\n",
    "print(frequency_distribution)\n",
    "\n",
    "# Cross-tabulation\n",
    "crosstab = pd.crosstab(filtered_df['numfriends'], filtered_df['SCF100_C'], rownames=['numfriends'], colnames=['SCF100_C'])\n",
    "\n",
    "print(\"\\nCross-tabulation of numfriends by SCF100_C:\")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22cb9c8",
   "metadata": {},
   "source": [
    "For univariate analysis of a ratio variable such as numfriends, you can calculate various descriptive statistics including frequencies, mean, median, standard deviation, and mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7dab179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies of numfriends:\n",
      "numfriends\n",
      "2.0     5170\n",
      "3.0     3916\n",
      "5.0     3135\n",
      "1.0     3067\n",
      "4.0     2935\n",
      "0.0     2689\n",
      "14.5    2548\n",
      "6.0     1706\n",
      "8.0      827\n",
      "7.0      532\n",
      "24.5     523\n",
      "NaN      449\n",
      "30.0     221\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Descriptive Statistics for numfriends:\n",
      "Mean: 4.750284205508086\n",
      "Median: 3.0\n",
      "Standard Deviation: 5.272239825076114\n",
      "Mode: [2.]\n"
     ]
    }
   ],
   "source": [
    "# Frequencies\n",
    "frequency_distribution = filtered_df['numfriends'].value_counts(dropna=False)\n",
    "\n",
    "# Descriptive statistics\n",
    "mean = filtered_df['numfriends'].mean()\n",
    "median = filtered_df['numfriends'].median()\n",
    "stddev = filtered_df['numfriends'].std()\n",
    "mode = filtered_df['numfriends'].mode().values  # mode() returns a Series, take the values\n",
    "\n",
    "print(\"Frequencies of numfriends:\")\n",
    "print(frequency_distribution)\n",
    "\n",
    "print(\"\\nDescriptive Statistics for numfriends:\")\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Standard Deviation: {stddev}\")\n",
    "print(f\"Mode: {mode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775d5d5",
   "metadata": {},
   "source": [
    "Bivariate analysis: \n",
    "t-test (comparing mean # of friends between visible minority and non-visible minority)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "783d2e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test Results:\n",
      "T-statistic: 10.102743758610377\n",
      "P-value: 5.9640357996091385e-24\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Split data into two groups\n",
    "group1 = filtered_df[filtered_df['vismin2_label'] == 'Not a Visible Minority']['numfriends']\n",
    "group2 = filtered_df[filtered_df['vismin2_label'] == 'Visible Minority']['numfriends']\n",
    "\n",
    "# Perform the t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, nan_policy='omit')\n",
    "\n",
    "print(\"T-test Results:\")\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f2b85",
   "metadata": {},
   "source": [
    " t-test groups vismin2(0 1)/variables numfriends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9aa0493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test Results:\n",
      "T-statistic: 10.102743758610377\n",
      "P-value: 5.9640357996091385e-24\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "# Split data into two groups\n",
    "group1 = filtered_df[filtered_df['vismin2'] == 0]['numfriends']\n",
    "group2 = filtered_df[filtered_df['vismin2'] == 1]['numfriends']\n",
    "\n",
    "# Perform the t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, nan_policy='omit')\n",
    "\n",
    "print(\"T-test Results:\")\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b28b2a",
   "metadata": {},
   "source": [
    "## ANOVA\n",
    "\n",
    "ANOVA, or Analysis of Variance, is a statistical technique used to determine if there are any statistically significant differences between the means of three or more independent groups. It is commonly used when comparing more than two groups to see if at least one group mean is different from the others.\n",
    "\n",
    "### Key Concepts:\n",
    "* Null Hypothesis (H0): Assumes that all group means are equal.\n",
    "* Alternative Hypothesis (H1): Assumes that at least one group mean is different.\n",
    "* F-statistic: The ratio of the variance between the group means to the variance within the groups. A higher F-statistic suggests that the group means are not all the same.\n",
    "* p-value: Helps determine the significance of the results. A p-value less than a chosen significance level (e.g., 0.05) leads to rejection of the null hypothesis.\n",
    "### Types of ANOVA:\n",
    "1. One-Way ANOVA: Compares the means of three or more independent groups based on one independent variable.\n",
    "1. Two-Way ANOVA: Examines the influence of two different independent variables on the dependent variable and can also assess the interaction between these variables.\n",
    "1. Repeated Measures ANOVA: Used when the same subjects are tested under different conditions (e.g., time points).\n",
    "### Example of One-Way ANOVA:\n",
    "Imagine a study where researchers want to test the effect of different diets on weight loss. The independent variable is the type of diet (e.g., Diet A, Diet B, Diet C), and the dependent variable is weight loss. ANOVA can determine if there is a statistically significant difference in weight loss between the diet groups.\n",
    "\n",
    "### Steps to Perform ANOVA:\n",
    "1. State the hypotheses: Formulate the null and alternative hypotheses.\n",
    "2. Calculate the F-statistic: Use statistical software or formulas to compute the F-statistic.\n",
    "3. Compare the F-statistic to the critical value: Determine whether to reject or fail to reject the null hypothesis.\n",
    "4. Post hoc tests (if necessary): If ANOVA indicates a significant difference, post hoc tests (like Tukey's HSD) can determine which specific groups are different.\n",
    "\n",
    "\n",
    "For our dataframe we want to compare mean # of friends between racial groups (original vismin_c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "303c2d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA F-statistic: 20.016378312830568\n",
      "ANOVA p-value: 2.0899985562466142e-37\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Drop rows with NaN values in the relevant columns\n",
    "anova_data = filtered_df[['numfriends', 'VISMIN_C']].dropna()\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "anova_results = stats.f_oneway(\n",
    "   *[anova_data['numfriends'][anova_data['VISMIN_C'] == group] for group in anova_data['VISMIN_C'].unique()]\n",
    ")\n",
    "\n",
    "print(\"ANOVA F-statistic:\", anova_results.statistic)\n",
    "print(\"ANOVA p-value:\", anova_results.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e69b79",
   "metadata": {},
   "source": [
    "### Interpreting the reuslts:\n",
    "\n",
    "* F-statistic: This tells you whether there is a statistically significant difference in the means across the groups.\n",
    "* p-value: If the p-value is below a certain threshold (commonly 0.05), you can reject the null hypothesis that the means are equal across the groups\n",
    "\n",
    "## Crosstab\n",
    "\n",
    "In this section we perform crosstab for nominal (visible minority) and ordinal variable (highest degree). \n",
    "1. create crosstab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8de2773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISMIN_C         1         2         3         4         5         6  \\\n",
      "ED_05                                                                  \n",
      "1         0.133846  0.192982  0.114780  0.010169  0.109856  0.089426   \n",
      "2         0.287692  0.234450  0.283019  0.088136  0.141170  0.200392   \n",
      "3         0.041538  0.042265  0.075472  0.077966  0.044148  0.075065   \n",
      "4         0.116154  0.125997  0.183962  0.186441  0.109856  0.156005   \n",
      "5         0.048462  0.057416  0.051887  0.122034  0.069815  0.052219   \n",
      "6         0.190000  0.197767  0.130503  0.427119  0.289528  0.224543   \n",
      "7         0.172308  0.138756  0.144654  0.054237  0.221766  0.186031   \n",
      "99        0.010000  0.010367  0.015723  0.033898  0.013860  0.016319   \n",
      "\n",
      "VISMIN_C         7         8         9        10        99       All  \n",
      "ED_05                                                                 \n",
      "1         0.214375  0.069542  0.134529  0.096608  0.108337  0.109892  \n",
      "2         0.226250  0.174296  0.253363  0.213965  0.210185  0.212173  \n",
      "3         0.059375  0.037852  0.044843  0.109584  0.057913  0.085107  \n",
      "4         0.146250  0.112676  0.139013  0.202274  0.110834  0.170611  \n",
      "5         0.049375  0.049296  0.069507  0.053700  0.043934  0.054477  \n",
      "6         0.188750  0.257923  0.230942  0.179471  0.158263  0.195577  \n",
      "7         0.101875  0.292254  0.112108  0.121017  0.131303  0.141244  \n",
      "99        0.013750  0.006162  0.015695  0.023381  0.179231  0.030919  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "crosstab = pd.crosstab(filtered_df['ED_05'], filtered_df['VISMIN_C'], margins=True, normalize='columns')\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a09c8",
   "metadata": {},
   "source": [
    "2. Chi-Square Test\n",
    "\n",
    "To assess the association between the two variables, you can perform a chi-square test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76a8bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Test Statistic: 1.1965048877363103\n",
      "P-value: 1.0\n",
      "Degrees of Freedom: 60\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, dof, ex = chi2_contingency(crosstab.iloc[:-1, :-1])\n",
    "\n",
    "print(f\"Chi-Square Test Statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c4df2",
   "metadata": {},
   "source": [
    "3. Interpret the Results:\n",
    "   \n",
    "* Chi-Square Statistic: Measures how the observed counts diverge from the expected counts.\n",
    "* P-value: If this value is below 0.05, it suggests a statistically significant association between the two variables.\n",
    "* Degrees of Freedom (DoF): This is calculated based on the number of categories in each variable."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "source_map": [
   10,
   117,
   121,
   125,
   128,
   132,
   134,
   143,
   146,
   150,
   157,
   162,
   166,
   171,
   177,
   181,
   187,
   198,
   202,
   204,
   208,
   215,
   221,
   233,
   238,
   257,
   262,
   275,
   278,
   291,
   318,
   331,
   343,
   347,
   352,
   359
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}